\documentclass[10pt,landscape]{article}
\usepackage{multicol}
\usepackage{calc}
\usepackage{ifthen}
\usepackage[landscape]{geometry}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{float}
\usepackage{ulem}
\usepackage{bm}
\usepackage{anysize}
\usepackage{mathrsfs}
% To make this come out properly in landscape mode, do one of the following
% 1.
%  pdflatex latexsheet.tex
%
% 2.
%  latex latexsheet.tex
%  dvips -P pdf  -t landscape latexsheet.dvi
%  ps2pdf latexsheet.ps


% If you're reading this, be prepared for confusion.  Making this was
% a learning experience for me, and it shows.  Much of the placement
% was hacked in; if you make it better, let me know...


% 2008-04
% Changed page margin code to use the geometry package. Also added code for
% conditional page margins, depending on paper size. Thanks to Uwe Ziegenhagen
% for the suggestions.

% 2006-08
% Made changes based on suggestions from Gene Cooperman. <gene at ccs.neu.edu>


% To Do:
% \listoffigures \listoftables
% \setcounter{secnumdepth}{0}


% This sets page margins to .5 inch if using letter paper, and to 1cm
% if using A4 paper. (This probably isn't strictly necessary.)
% If using another size paper, use default 1cm margins.
\ifthenelse{\lengthtest { \paperwidth = 11in}}
	{ \geometry{top=.5in,left=.5in,right=.5in,bottom=.5in} }
	{\ifthenelse{ \lengthtest{ \paperwidth = 297mm}}
		{\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} }
		{\geometry{top=1cm,left=1cm,right=1cm,bottom=1cm} }
	}

% Turn off header and footer
\pagestyle{empty}
 

% Redefine section commands to use less space
\makeatletter
\renewcommand{\section}{\@startsection{section}{1}{0mm}%
                                {-1ex plus -.5ex minus -.2ex}%
                                {0.5ex plus .2ex}%x
                                {\normalfont\large\bfseries}}
\renewcommand{\subsection}{\@startsection{subsection}{2}{0mm}%
                                {-1explus -.5ex minus -.2ex}%
                                {0.5ex plus .2ex}%
                                {\normalfont\normalsize\bfseries}}
\renewcommand{\subsubsection}{\@startsection{subsubsection}{3}{0mm}%
                                {-1ex plus -.5ex minus -.2ex}%
                                {1ex plus .2ex}%
                                {\normalfont\small\bfseries}}
\makeatother

% Define BibTeX command
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

% Don't print section numbers
\setcounter{secnumdepth}{0}


\setlength{\parindent}{0pt}
\setlength{\parskip}{0pt plus 0.5ex}


% -----------------------------------------------------------------------

\begin{document}

\raggedright
\footnotesize
\begin{multicols}{3}


% multicol parameters
% These lengths are set only within the two main columns
%\setlength{\columnseprule}{0.25pt}
\setlength{\premulticols}{1pt}
\setlength{\postmulticols}{1pt}
\setlength{\multicolsep}{1pt}
\setlength{\columnsep}{2pt}

\begin{center}
     \Large{\textbf{Computer Vision Midterm2}} \\
\end{center}

\section{Pinhole Camera Model}
\subsection{Projection Equation}  $x = f X/Z$, $y = f X/Z$, $z = f$\\
The $2D$ perspective images of $3D$ parallel lines that are not parallel to the image plane are not parallel and intersect at the ``vanishing point''.\\
\subsection{3D Line Equations}
$P(X_P, Y_P, Z_P), Q(X_Q, Y_Q, Z_Q), R(X, Y, Z)$\\
$R=P+\lambda(Q-P)$\\
$X=X_P + \lambda(X_Q - X_P)$\\
$Y=Y_P + \lambda(Y_Q - Y_P)$\\
$Z=Z_P + \lambda(Z_Q - Z_P)$\\
$x=f[X_P + \lambda(X_Q - X_P)]/[Z_P + \lambda(Z_Q - Z_P)]$\\
$y=f[Y_P + \lambda(Y_Q - Y_P)]/[Z_P + \lambda(Z_Q - Z_P)]$\\
$z=f$\\
Assuming that $Z_Q \neq Z_P$:\\
$\lim\limits_{\lambda\to\infty}x \to f\frac{X_Q - X_P}{Z_Q - Z_P}$, $\lim\limits_{\lambda\to\infty}y \to f\frac{Y_Q - Y_P}{Z_Q - Z_P}$, $\lim\limits_{\lambda\to\infty}z \to f$\\
When $Z_Q == Z_P:$\\
$\lim\limits_{\lambda\to\infty}x \to \infty$, $\lim\limits_{\lambda\to\infty}y \to \infty$, $\lim\limits_{\lambda\to\infty}z \to f$\\
The image of the IDEAL point of a line parallel to the
image plane is an IDEAL point.\\
The image of a circle is the intersection of a cone and
the image plane and it is in general an ellipse.\\

\section{2D Transformation}
%------------
\subsection{translation}
\begin{equation*}
\left[ \begin{array}{c}
x'\\
y'\\
1
\end{array} \right ] = \left[ \begin{array}{ccc}
1&0&t_x\\
0&1&t_y\\
0&0&1
\end{array} \right ]\left[ \begin{array}{c}
x\\
y\\
1
\end{array} \right ] 
\end{equation*}
$\#D.O.F \ : 2$
Invariant:\\
Preserves: orientation + ...
%------------
\subsection{Rigid(Euclidean)}
\begin{equation*}
\left[ \begin{array}{c}
x'\\
y'\\
1
\end{array} \right ] = \left[ \begin{array}{ccc}
cos\theta & -sin\theta&t_x\\
sin\theta&cos\theta&t_y\\
0&0&1
\end{array} \right ] \left[ \begin{array}{c}
x\\
y\\
1
\end{array} \right ] 
\end{equation*}
$\#D.O.F \ : 3$\\
Invariant: lengths, areas\\
Preserves: lengths + ...
%------------
\subsection{Similarity(scaled Euclidean)}

\begin{equation*}
\left[ \begin{array}{c}
p'\\
1
\end{array} \right ] = \left[ \begin{array}{cc}
sR&t\\
0&1
\end{array} \right ]\left[ \begin{array}{c}
p\\
1
\end{array} \right ] 
\end{equation*}
$\#D.O.F \ : 4$\\
Invariant: Ratios of lengths, angles\\
Preserves: angles + ...
%------------
\subsection{affine}

\begin{equation*}
\left[ \begin{array}{c}
p'\\
1
\end{array} \right ] = \left[ \begin{array}{cc}
A&b\\
0&1
\end{array} \right ] \left[ \begin{array}{c}
p\\
1
\end{array} \right ] 
\end{equation*}
$\#D.O.F \ : 6$\\
Invariant: Parallellism, ratio of areas, ratio of lengths on parallel lines (e.g midpoints), linear combinations of vectors (centroids). \\
Preserves: parallelism + ...
%------------
\subsection{projective}
A projective transformation of Pn onto itself is completely determined by its action on n+2 points.\\
\begin{equation*}
\left[ \begin{array}{c}
p'\\
1
\end{array} \right ] \sim \left[ \begin{array}{cc}
A&b\\
c^T&1
\end{array} \right ] \left[ \begin{array}{c}
p\\
1
\end{array} \right ] 
\end{equation*}
$\#D.O.F \ : 8$\\
Invariant: Concurrency, collinearity, cross ratio\\
Preserves: straight lines
%------------
%\subsection{Summary of 2D Transformation}
\section{Coordinate Systems}
$P_C = M_{ext}\times P_w$, $M_{ext} = R_{(X)}R_{(Y)}R_{(Z)}T$
%------------
\subsection{3D Rotation}
\textbf{CLOCKWISE} Rotation around the coordinate axes (left hand):
\begin{equation*}
\left[ \begin{array}{c}
X'\\
Y'\\
Z'
\end{array} \right ] = R*\left[ \begin{array}{c}
X\\
Y\\
Z
\end{array} \right ]
\end{equation*}

\begin{equation*}
R_x(\alpha) = \left[ \begin{array}{ccc}
1&0&0\\
0&cos\alpha & -sin\alpha\\
0 & sin\alpha&cos\alpha
\end{array} \right ]
\end{equation*}

\begin{equation*}
R_y(\beta) = \left[ \begin{array}{ccc}
cos\beta&0&sin\beta\\
0&1&0\\
-sin\beta&0&cos\beta
\end{array} \right ]
\end{equation*}

\begin{equation*}
R_z(\gamma) = \left[ \begin{array}{ccc}
cos\gamma&-sin\gamma&0\\
sin\gamma&cos\gamma&0\\
0&0&1
\end{array} \right ]
\end{equation*}
%------------
\subsection{Translation}
\begin{equation*}
T = \left[ \begin{array}{cccc}
1&0&0&t_x\\
0&1&0&t_y\\
0&0&1&t_z\\
0&0&0&1
\end{array} \right ]
\end{equation*}

%------------
%------------





\section{Image processing}

%------------
\subsection{Spatial Filtering}
Low-pass filters eliminate/attenuate high frequency components in the frequency domain (sharp image details), and result in image blurring.\\
High-pass filters attenuate/eliminate low-frequency components (resulting in sharpening edges and other sharp details).\\
Band-pass filters remove selected frequency regions
between low and high frequencies (for image restoration, not enhancement).\\

%------------
\subsection{Noise}
Mean $\mu = \frac{1}{N}\sum^N_{i=1}x_i$\\
Variance $\sigma^2 = \frac{1}{N-1} \sum^N_{i=1}(x_i - \mu)^2$\\
Gaussian $N(\mu, \sigma^2) \sim \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{x\sigma^2}}$\\
Additive noise $I(i,j) = \Hat{I}(i,j) + N(i,j)$\\
Multiplicative noise  $I(i,j) = \Hat{I}(i,j) \times N(i,j)$\\
Impulsive noise (salt and pepper): 
\begin{equation*}  
I(i,j) = \left\{  
     \begin{array}{cc}  
     \Hat{I}(i,j), & x < l\\  
     i_{min} + y(i_{max} - i_{min}), & x \leq l\\   
     \end{array}  
\right.  
\end{equation*}  

%------------
\subsection{Smoothing Filters}
They are used for blurring and noise reduction. Blurring is performed as pre-processing to remove small detail or bridge curve gaps. Noise reduction can be done by linear or nonlinear filtering.\\
Linear smoothing Filters are simply averaging filters. They compute the average of the filters under the mask. They reduce sharp transitions. They are low pass filters.\\

\subsection{Linear Filtering}
\begin{equation*}
\text{BOX Filter: \   } \frac{1}{9}\left[ \begin{array}{ccc}
1 & 1 & 1\\
1 & 1 & 1\\
1 & 1 & 1
\end{array} 
\right]
\end{equation*}

Reduce Noise:\\
Expected value of a pixel $E[I_i] = \hat{I}_i \to \frac{1}{mn}\sum_i^{mn}\hat{I}_i$\\
Variance of a pixel $E[(I_i - E[I_i])^2] = \sigma^2 \to \frac{\sigma^2}{mn}$\\
The bigger the mask, more neighbors contribute; smaller noise variance of the output; bigger noise spread; more blurring; more expensive to compute.

\begin{equation*}
    \text{Weighted Average Filter: } w(s,t) = Ke^{\frac{s^2 + t^2}{2\sigma^2}}
\end{equation*}
Gives more weight at the central pixel and less weights to the neighbors. The farther away the neighbors, the smaller the weight. Less blurring of edges.\\
Both, the BOX filter and the Gaussian filter are
separable. First convolve each row with a 1D filter. Then convolve each column with a 1D filter.
%------------
\subsection{Nonlinear Filtering}
Limitation of averaging: Signal frequencies shared with noise are lost, resulting in blurring. Impulsive noise is diffused but not removed. It spreads pixel values, resulting in blurring.\\
Replace each pixel with the \textbf{MEDIAN} value of all the pixels in the neighborhood.\\
Properties: Non-linear; Does not spread the noise
Can remove spike noise; Expensive to run.


\section{Image Features}
%------------
\subsection{Edge Detection}

\subsubsection{Prewitt}
\begin{equation*}
\text{vertical: } \left[ \begin{array}{ccc}
-1 & 0 & 1\\
-1 & 0 & 1\\
-1 & 0 & 1
\end{array}  
\right]
\text{horizontal: } \left[ \begin{array}{ccc}
-1 & -1 & -1\\
0 & 0 & 0\\
1 & 1 & 1
\end{array} \right]
\end{equation*}

\subsubsection{Sobel}
\begin{equation*}
\text{vertical: } \left[ \begin{array}{ccc}
-1 & 0 & 1\\
-2 & 0 & 2\\
-1 & 0 & 1
\end{array}  
\right]
\text{horizontal: } \left[ \begin{array}{ccc}
-1 & -2 & -1\\
0 & 0 & 0\\
1 & 2 & 1
\end{array} \right]
\end{equation*}

\begin{equation*}
\text{Magnitude  } G = \sqrt{G_x^2 + G_y^2}
\end{equation*}
\begin{equation*}
\text{Orientation  } \Theta = \arctan(\frac{G_y}{G_x})
\end{equation*}

\subsubsection{CANNY ENHANCER}
The input is image $I$; $G$ is a zero mean Gaussian filter (std = $\sigma$)\\
1. $J = I \times G$ (smoothing)\\
2. For each pixel $(i,j)$: (edge enhancement)\\
Compute the image gradient $\nabla J(i,j) = (Jx(i,j),Jy(i,j))’$ \\
Estimate edge strength
$E_s(i,j) = \sqrt{(J_x^2(i,j) + J_y^2(i,j))}$\\
Estimate edge orientation
$E_o(i,j) = arctan(J_x(i,j)/J_y(i,j))$\\
The output are images $E_s$ and $E_o$


\subsubsection{NONMAX SUPRESSION}
The inputs are $E_s$ \& $E_o$ (outputs of CANNY\_ENHANCER)\\
Consider 4 directions $D = \{0, 45, 90, 135\}$ w.r.t. x\\
For each pixel $(i,j)$ do:\\
Find the direction $d\in D$ s.t. $d\sim E_o(i,j)$ (normal to the edge)\\
If $E_s(i,j)$ is smaller than at least one of its neigh. along d\\
$I_N(i,j)=0$\\
Otherwise, $I_N(i,j)= E_s(i,j)$\\
The output is the thinned edge image $I_N$

\subsubsection{Thresholding}
Edges are found by thresholding the output of NONMAX SUPRESSION. If the threshold is too high: Very few (none) edges High MISDETECTIONS, many gaps. If the threshold is too low: Too many (all pixels) edges High FALSE POSITIVES, many extra edges.

\subsection{Corner}

\subsubsection{Harris Corner Detection}
Compute the Image Gradient\\
$I_x = G_{x,s} \times I$, $Iy = G_{y,s} \times I$\\
Compute products of derivatives at each pixel\\
$I^2_x = I_x \cdot I_x$, $I^2_y = I_y \cdot I_y$ and $I_{xy} = I_x \cdot I_y$\\
Compute the sums of the products at each pixel using a window averaging\\
$S^2_x = Gs’ \times I^2_x$, $S^2_y = Gs’ \times I^2_y$, $S_{xy} = Gs’ \times I_{xy}$\\
Define the Matrix at each pixel $M = [S^2_x\ \  S_{xy} ; S_{xy}\ \ S^2_y]$\\
Compute the response $R = det(M) - k\ trace(M)^2$\\
Threshold R \\
Compute Nonmax suppression

\section{Grouping edges}
Edge detectors find “edges” (pixel level)
To perform image analysis: edges must be grouped into entities such as contours (higher level). Canny does this to certain extent: the detector finds chains of edges.
%------------
\subsection{Hough Transform}
Given a set of collinear edge points, each of them have associated a line in parameter space. These lines intersect at the point (m,n) corresponding to the parameters of the line in the image space. At each point of the (discrete) parameter space, count how many lines pass through it. Use an array of counters.Can be thought as a “parameter image”. The higher the count, the more edges are collinear in the image
space. Find a peak in the counter array
This is a “bright” point in the parameter image. It can be found by thresholding.

\subsubsection{Normal equation}
\begin{equation*}
    \rho = x\ cos\theta + y\ sin\theta \text{\ \ \ \ $x,\ y$ on the line}
\end{equation*}

\begin{equation*}
\left[ \begin{array}{cc}
\rho<0\ \  \theta  < 0 & \rho>0\ \  \theta > 0\\
\rho<0\ \  \theta > 0 & \rho>0\ \  \theta < 0
\end{array} \right]-\frac{D}{2} \leq \rho \leq \frac{D}{2}\ -90\leq\theta\leq90
\end{equation*}
\begin{equation*}
    y=k \to \rho = k, \theta = 90 \ \ \ \ \ \     x=k \to \rho = k, \theta = 0
\end{equation*}

\subsection{Mean Shift} 
1. Choose a window size.\\
2. Choose the initial location of the search window.\\
3. Compute the mean location in the search window.\\
4. Center the window at the location computed in 3.\\
5. Repeat steps 3 and 4 until convergence.

\subsection{Merging Algorithm}
Consider two regions:\\
Let $g_1$, $g_2$, $\dots$, $g_{m1}$ be the gray values in $R1$\\
Let $g_{m1+1}$, $g_{m1+2}$, $\dots$, $g_{m1+m2}$ be the gray values in $R2$\\
Assume regions are constant with uncorrelated zero mean Gaussian noise.\\
Two possible HYPOTHESES:\\
\textbf{$H_0$}: Both regions belong to the same object and the residual values have distribution $N(0, \sigma_0^2)$.\\
\textbf{$H_1$}: Each region belongs to a different object and their residual values have distributions $N(0, \sigma_1^2)$ and $N(0, \sigma_2^2)$.\\
Assume $H_0$ is \textbf{TRUE}: Estimate $\mu_0$ and $\sigma_0$:
\begin{equation*}
    \mu_0 = \frac{1}{m_1+m_2}\sum_{g_i\in R_1\cup R_2}g_i,\ \ \sigma^2_0 = \frac{1}{m_1+m_2}\sum_{g_i\in R_1\cup R_2}(g_i - \mu_0)^2
\end{equation*}
Compute the probability of independently drawing $g_1$, $g_2$, $\dots$, $g_{m1+m_2}$ with distribution $N(\mu_0,\sigma_0^2)$:
\begin{equation*}
\begin{aligned}
P\left ( g_1, g_2,...,g_{m_1+m_2}|H_0 \right )&=\prod^{m_1+m_2}_{i=1}P(g_i|H_0)\\
&=\frac{1}{(\sqrt{2\pi}\sigma_0)^{m_1+m_2}}e^{-(m_1+m_2)/2}
\end{aligned}
\end{equation*}

Assume $H_1$ is \textbf{TRUE}: Estimate $\mu_1$ and $\sigma_1$, $\mu_2$ and $\sigma_2$:
\begin{equation*}
    \mu_j = \frac{1}{m_j}\sum_{g_i\in R_j}g_i,\ \ \sigma^2_0 = \frac{1}{m_j}\sum_{g_i\in R_j}(g_i - \mu_j)^2, \ \ j = 1,2
\end{equation*}
Compute the probability of independently drawing $g_1$, $g_2$, $\dots$, $g_{m1}$ with distribution $N(\mu_1,\sigma_1^2)$, and $g_{m1+1}$, $g_{m1+2}$, $\dots$, $g_{m1+m2}$ with
distribution $N(\mu_2,\sigma_2^2)$:
\begin{equation*}
P\left (g_1,...,g_{m1}|H_1 \right )
=\frac{1}{(\sqrt{2\pi}\sigma_1)^m_1}e^{-m_1/2}
\end{equation*}

\begin{equation*}
P\left (g_{m_1 +1},...,g_{m1_m2}|H_1 \right )
=\frac{1}{(\sqrt{2\pi}\sigma_2)^m_2}e^{-m_2/2}
\end{equation*}

\begin{equation*}
P\left (g_1, g_2,...,g_{m_1+m_2}|H_1 \right )=\frac{1}{(\sqrt{2\pi})^{m_1+m_2}\sigma_1^{m1}\sigma_2^{m2}}e^{-(m_1+m_2)/2}
\end{equation*}

\begin{equation*}
L = \frac{P\left (g_1, g_2,...,g_{m_1+m_2}|H_1 \right )}{P\left (g_1, g_2,...,g_{m_1+m_2}|H_0 \right )}=\frac{\sigma_0^{m+n}}{\sigma_1^m\sigma_2^n}
\end{equation*}
If $L < 1$, $H_0$ is more likely than $H_1$: Merge the regions!

\subsection{Feature Matching}
\begin{equation*}
    SSD = \sum_{[i,j] \in R}(f(i,j) - g(i,j))^2
\end{equation*}

\begin{equation*}
   c_{fg}= \sum_{[i,j] \in R}f(i,j)g(i,j)
\end{equation*}
\begin{equation*}
N_{fg} = \sum_{[i, j]\in R}\hat{f}(i, j)\hat{g}(i, j),\ \ \hat{f} = \frac{f}{||f||}, \ \  \hat{g} = \frac{g}{||g||}
\end{equation*}


\subsection{SIFT + RANSAC for Homography}
Choose 2 overlapping images.\\
Find SIFT features for each image.\\
Match SIFT features to get initial point correspondences.\\
Run RANSAC:\\
1. Select minimal number of points (4), find homography.\\
2. Check number of data points consistent with this fit.\\
3. Good enough?  $\to$ Find homography using all inliers.\\


\subsection{Homograph Estimation}
\begin{equation*}
\left[ \begin{array}{c}
x'\\
y'\\
1
\end{array} \right] = \left[ \begin{array}{ccc}
h_{11} & h_{12} & h_{13} \\
h_{21} & h_{22} & h_{23} \\
h_{31} & h_{32} & h_{33} 
\end{array} \right]\left[ \begin{array}{c}
x\\
y\\
1
\end{array} \right] 
\end{equation*}

\begin{equation*}
\left[ \begin{array}{cccccccc}
x_1 & y_1 & 1 & 0 & 0 & 0 & -x_1x_1'& - y_1x_1'\\
0 & 0 & 0 & x_1 & y_1 & 1 & -x1y_1'& -y_1y_1'\\
...
\end{array} \right] 
\end{equation*}
\begin{equation*}
Ah=b \to h = (A^TA)^{-1}(A^Tb)
\end{equation*}




\subsection{Image (un)Warping}
$I = (1-a)\ (1-b)\ I(i,j)+a\ (1-b)\ I(i+1,j)$\\
 \ \   $+(1-a)\ b\ I(i,j+1)+a\ b\ I(i+1, j+1)$





%------------------------------
\section{Stereo Vision}
The ability to infer information on the 3D structure and distance of a scene from two or more images taken from different viewpoints.
%------------------------------
%------------------------------
\subsection{A simple stereo system}
\begin{equation*}
    \frac{T+x_l-x_r}{Z-f} = \frac{T}{Z},\ Z = f\frac{T}{x_r-x_l}, \ Z = f\frac{T}{d}
\end{equation*}
\textbf{Disparity}: $d=x_r-x_l$



%------------------------------
%------------------------------
\subsection{Epipolar Geometry}
Epipoles:
\begin{itemize}
    \item  $e_l$: left image of $O_r$
    \item  $e_r$: right image of $O_l$
\end{itemize}

Epipolar plane:
\begin{itemize}
    \item Three points: $O_l$, $O_r$, and $P$ define an epipolar plane
\end{itemize}

Epipolar lines and epipolar constraint:
\begin{itemize}
    \item Intersections of epipolar plane with the image planes
    \item Corresponding points are on ``conjugate'' epipolar lines 
\end{itemize}


Find Epipoles, given $p_l$:
\begin{itemize}
    \item consider its epipolar line: $p_l, e_l$
    \item find epipolar plane: $O_l, p_l, e_l$
    \item intersect the epipolar plane with the right image plane
    \item search for $p_r$ on the right epipolar line
\end{itemize}
Parallel Cameras: 
\begin{itemize}
    \item Epipoles are at infinity
    \item Epipolar lines are parallel to the baseline
\end{itemize}


%------------------------------
%------------------------------
\subsection{Essential Matrix}

The \textbf{ESSENTIAL} matrix is a $3\times3$ matrix that “encodes” the epipolar geometry of two views. Given a point in an image, multiplying by the Essential Matrix, will tell us the \textbf{EPIPOLAR} line in the second image where the corresponding point must be.\\
\begin{equation*}
    E=RS,\ P^T_rEP_l = 0,\ p^T_rEp_l = 0 
\end{equation*}
Essential matrix has rank 2, and depends only on the EXTRINSIC Parameters ($R$ \& $T$).
\begin{equation*}
T =\left[ \begin{array}{ccc}
T_x & T_y & T_z
\end{array} \right ], S = \left[ \begin{array}{ccc}
0 & -T_z & T_y\\
T_z & 0 & -T_x\\
-T_y & T_x & 0
\end{array} \right ]
\end{equation*}
$p_r$ belongs to epipolar line in the right image defined by
\begin{equation*}
    l_r = Ep_l
\end{equation*}
$p_l$ belongs to epipolar line in the left image defined by 
\begin{equation*}
    l_l = E^Tp_r
\end{equation*}
Epipoles belong to the epipolar lines, and they belong to all the epipolar lines:
\begin{equation*}
    e^T_rE=0, Ee_l=0
\end{equation*}



%------------------------------
%------------------------------
\subsection{Fundamental Matrix}
The essential matrix uses \textbf{CAMERA} coordinates. To use image coordinates we must consider the \textbf{INTRINSIC} camera parameters.
\begin{equation*}
    p_l=M_l^{-1}\bar{p_l},\ p_r=M_r^{-1}\bar{p_r}, \bar{p_r}^TF\bar{p_l}=0,\ F=M_r^{-T}RSM^{-1}_l
\end{equation*}


Fundamental matrix has rank 2, and depends on the INTRINSIC and EXTRINSIC Parameters ($f$, etc ; $R$ \& $T$). Analogous to the Essential matrix, the Fundamental matrix also tells how points in each image are related to epipolar lines in the other image.


%------------------------------
%------------------------------
\subsection{Eight Points Algorithm}
\begin{itemize}
    \item $F$ is a $3\times3$ matrix (9 entries) but rank 2
    \item \textbf{HOMOGENEOUS} linear system with 9 unknowns
    \item Need $m \geq 8$; solution will be up to a constant
\end{itemize}
\begin{equation*}
    \left[ \begin{array}{ccc}
x_1x'_1 & ... & x_mx'_m\\
 x_1y'_1 & ... & x_my'_m \\
 x_1 & ... & x_m\\
 y_1x'_1 & ... & y_mx'_m\\
 y_1y'_1 & ... & y_my'_m\\
 y_1 & ... & y_m\\
 x'_1 & ... & x'_m\\
 y'_1 & ... & y'_m\\
 1 & ... & 1
    \end{array} \right ]^T    \left[ \begin{array}{c}
f_11\\
f_21\\
f_31\\
f_12\\
f_22\\
f_32\\
f_13\\
f_23\\
f_33
    \end{array} \right ] = 0
\end{equation*}
Assume that we need to find the non trivial solution of:
\begin{equation*}
    Ax=0
\end{equation*}
with $m$ equations and $n$ unknowns, $m \geq n – 1$ and rank$(A) = n-1$. Since the norm of $x$ is arbitrary, we will look for a solution
with norm $||x|| = 1$. We want $Ax$ as close to $0$ as possible and $||x|| =1$:
\begin{equation*}
    \min_x ||Ax||^2\ \ \text{s.t. } ||x||^2 = 1,\ ||Ax||^2 = x^TA^TAx
\end{equation*}
Define the following cost:
\begin{equation*}
\mathscr{L}(x) = x^TA^TAx - \lambda(x^Tx - 1)
\end{equation*}
This cost is called the\textbf{ LAGRANGIAN cost} and $\lambda$ is called the \textbf{LAGRANGIAN multiplier}. The Lagrangian incorporates the constraints into the cost function by introducing extra variables.
\begin{itemize}
    \item Construct the $m \times 9$ matrix $A$
    \item Find the SVD of $A$: $A = UDV^T$
    \item The columns of $V$ are the eigenvectors of $A^TA$; the last one corresponds to the smallest eigenvalue
    \item The entries of $F$ are the components of the last column of $V$ corresponding to the least s.v.
\end{itemize}
F must be singular. To enforce it:
\begin{itemize}
    \item Find the SVD of $F$: $F = U_fD_fV_f^T$
    \item Set smallest s.v. of $F$ to $0$ to create $D’_f$
    \item Recompute $F: F = U_fD’_fV_f^T$
\end{itemize}



%------------------------------
%------------------------------
\subsection{3D Reconstruction}
Intrinsic:
\begin{itemize}
    \item $f_1$ and $f_2$: focal lengths
    \item $c_1$ and $c_2$: principal points
    \item Pixel size
\end{itemize}
•Extrinsic
\begin{itemize}
    \item Transformation $(R,T)$ between cameras
\end{itemize}


%------------------------------
\section{Motion}

%------------------------------
%------------------------------
\subsection{Time to Collision}
An object of height $L$ moves with constant velocity $v$. 
\begin{itemize}
    \item At time $t=0$ the object is at $D(0) = D_0$
    \item At time $t$ it is at $D(t) = D_0 - vt$
    \item It will crash with the camera at time $\tau = D_0/v$
\end{itemize}


%------------------------------
%------------------------------
\subsection{Comparison}
Stereo:
\begin{itemize}
    \item Two or more frames
    \item Baseline is usually larger
    \item Stereo images are taken at the same time
\end{itemize}

Motion
\begin{itemize}
    \item $N$ frames
    \item Motion disparities tend to be smaller
    \item Motion disparities can be due to scene motion
    \item There can be more than 1 transf between frames
\end{itemize}




%------------------------------
%------------------------------
\subsection{Motion Field (MF)}
The MF assigns a velocity vector to each pixel in the image.\\
These velocities are INDUCED by the RELATIVE MOTION btw the camera and the 3D scene.\\
The MF can be thought as the \textit{projection} of the 3D velocities on the image plane.\\
The relative velocity of $P$ $w.r.t.$ camera:
\begin{equation*}
    V = - T - \omega \times P,\ T = \left[ \begin{array}{c}
    T_x\\
    T_y\\
    T_z
\end{array} \right ],\ \omega = \left[ \begin{array}{c}
    \omega_x\\
    \omega_y\\
    \omega_z
\end{array} \right ]
\end{equation*}
Translation velocity and rotation angular velocity.\\


\subsubsection{The velocity of p}
\begin{equation*}
    v = f\frac{V}{Z} - p\frac{V_z}{Z}
\end{equation*}

\begin{equation*}
    v_x = \frac{T_zx - T_xf}{Z} - \omega_yf + \omega_zy + \frac{\omega_xxy}{f} - \frac{\omega_yx^2}{f}
\end{equation*}

\begin{equation*}
    v_y = \frac{T_zy - T_yf}{Z} + \omega_xf - \omega_zx - \frac{\omega_yxy}{f} + \frac{\omega_xy^2}{f}
\end{equation*}

Translational component and rotational component. The rotational component is independent of depth $Z$!

\subsubsection{Pure Translation}


\begin{equation*}
    v_x = (x-x_0)\frac{T_z}{Z} ,\ v_y = (y-y_0)\frac{T_z}{Z} 
\end{equation*}
The motion field in this case is RADIAL. It consists of vectors passing through $p_0 = (x_0,y_0)$.

$Tz > 0$, (camera moving towards object)
\begin{itemize}
    \item the vectors point away from $p_0$
    \item $p_0$ is the POINT OF EXPANSION
\end{itemize}

$Tz < 0$, (camera moving away from object)
\begin{itemize}
    \item the vectors point towards $p_0$
    \item $p_0$ is the POINT OF CONTRACTION
\end{itemize}

If $T_z\neq 0$ the MF is RADIAL with all vectors pointing towards (or away from) a single point $p_0$.
If $T_z = 0$, all motion field vectors are parallel to each other and inversely proportional to depth. 
The length of the MF vectors is inversely proportional to depth $Z$.
If $T_z \neq 0$ it is also directly proportional to the distance between $p$ and $p_0$.
\begin{equation*}
    p_0 = \left[ \begin{array}{c}
         x_0 \\
         y_0\\
         f
    \end{array}\right]= \left[ \begin{array}{c}
         fT_x/T_z \\
         fT_y/T_z\\
         f
    \end{array}\right]
\end{equation*}
$p_0$ is the vanishing point of the direction of translation.
$p_0$ is the intersection of the ray parallel to the translation vector and the image plane.


%------------------------------
%------------------------------
\subsection{OPTICAL FLOW}
We will use the apparent motion of brightness patterns observed in an image sequence. This motion is called OPTICAL FLOW.
\textbf{MF $\neq$ OF.} Consider a smooth, lambertian, uniform sphere rotating around a diameter, in front of a camera. MF $\neq 0$ since the points on the sphere are moving; OF $= 0$ since there are no moving patterns in the images. \\
\textbf{MF $\neq$ OF.} Consider a still, smooth, specular, uniform sphere, in front of a stationary camera and a moving light source. MF $= 0$ since the points on the sphere are not moving; OF $\neq 0$  since there is a moving pattern in the images. \\
Never the less, keeping in mind that MF $\neq$ OF, we will assume that the apparent brightness of moving objects remains constant and hence we will estimate OF instead (since MF cannot really be observed!).\\
The Image Brightness Constancy Assumption only provides the OF component in the direction of the spatial image gradient.
\subsubsection{Differential Techniques}
Based on spatial and temporal variations of the image brightness at all pixels. Used to compute DENSE OF.\\
Assumptions:
\begin{itemize}
    \item Brightness Constancy: $(\nabla E)^Tv+E_t = \epsilon \sim 0$, where ε accounts for noise and model errors
    \item OF is constant in small patches
\end{itemize}
\begin{equation*}
\left[ \begin{array}{cc}
\sum I^2_x & \sum I_xI_y\\
\sum I_xI_y & \sum I^2_y
\end{array} \right] \left[ \begin{array}{c}
V_x\\
V_y
\end{array} \right]= -\left[ \begin{array}{c}
\sum I_xI_t\\
\sum I_yI_t
\end{array} \right]
\end{equation*}
Aperture Problem：
\begin{itemize}
    \item One $e.v. = 0$ -> no corner, just an edge. At edges, $A^TA$ becomes singular.
    \item Two $e.v. = 0$ -> no corner, homogeneous region. At homogeneous regions, $A^TA$ becomes 0 (0 eigenvalues).
\end{itemize}

\subsubsection{Matching Techniques}
Estimates OF only at localized features. Produces SPARSE OF mappings.\\
Fails for large motions. Traditional LK is just refining a position estimate. We must be close to the right answer, and it only finds a local min. We can increase range of LK methods by using a coarse to fine image pyramid, so at each level the refinement is small. \\
If object moves fast, the brightness changes quickly and small masks fail to estimate the spatiotemporal derivatives. Pyramids can be used to compute large optical flow vectors.\\
\textbf{Pyramids} is very useful for image representation. Built by using multiple copies at different resolutions. Each level in the pyramid is $1/4$ size of the previous level (half columns, half rows). The lowest level has the highest resolution. The highest level has the lowest resolution.\\
Blur the image using a Gaussian filter, before \textbf{down-sampling}. Throw away every other row and column to create an image at $1/2$ of the scale. It happens when your sampling rate is not high enough to capture the amount of detail change.\\
\textbf{Up-sampling}. Interpolation via Convolution: Nearest-neighbor / Linear / Gaussian interpolation.



%------------------------------
\section{Tracking}
Basic Template Matching Assumptions:
\begin{itemize}
    \item A snapshot of the target can be used to describe it
    \item Target does not change (much) between frames
    \item Motion is mostly translational
\end{itemize}

%------------------------------
%------------------------------
\subsection{Lucas Kanade tracker}
\begin{equation*}
\left[ \begin{array}{cc}
\sum I^2_x & \sum I_xI_y\\
\sum I_xI_y & \sum I^2_y
\end{array} \right] \left[ \begin{array}{c}
V_x\\
V_y
\end{array} \right]= -\left[ \begin{array}{c}
\sum I_xI_t\\
\sum I_yI_t
\end{array} \right]
\end{equation*}
This is the matrix used for corner detection! Assumptions: brightness constancy assumption; all points in the template moved the same.\\
We can remove potential error sources by first normalizing the template and the local search window, by taking off the mean and dividing by the standard deviation.

%------------------------------
%------------------------------
\subsection{Circulant tracker}
\textbf{We want} to use a large number of samples (dense sampling); the samples themselves are high dimensional (hundreds, thousands of pixels); to learn a new classifier at each frame; test many unlabeled samples to find a “good” positive example.\\
\textbf{Solution}: Use “circulant” matrices. Make computations in the \textbf{FREQUENCY} domain instead of multiplying matrices, we can multiply element by element
instead of inverting matrices, we can divide element by element.\\
\textbf{Price we pay}: We need to go to the Frequency domain and come back.\\
$C(x)$ Circulant Matrix with constant diagonals.\\
Permutation Matrix: $P^{-1} = R^T$.\\



%------------------------------
%------------------------------
\subsection{Dynamics-based Tracking}
Use dynamics to PREDICT and ESTIMATE the position of the target. Reduces search space for the target. Improves the estimates of the location since measurements are noisy.\\
Get dynamics: Prior information, modeling, identification. Common assumptions: “random” walk; constant velocity; constant acceleration.\\
“Simple” dynamics might fail if there is prolonged occlusion. We can use tools from system identification (Hankel matrix) to predict future measurements without assuming a dynamic model.\\
Given a sequence of measurements of d-dimensional vectors $y_1,\ y_2,\ y_3$, its Hankel matrix is defined as:
\begin{equation*}
    H_y = \left [\begin{array}{cccc}
        y_1 & y_2 & ... & y_p\\
        y_2 & y_3 & ... & y_{p+1}\\
        : & : & ... & :\\
        y_m & y_{m+1} & ... & y_{m+p-1}
    \end{array} \right ] _{m\times p}
\end{equation*}
Rank$(Hy)$ measures the complexity of the underlying
dynamics: after we have “enough” measurements the rank of the Hankel matrix does not increase.\\
Model the dynamics using a simple regressive model. Regressor：$y_k = \sum^{\text{Rank}(H_y)}_{i=1} a_iy_{k-i}$. Rank$(H) = n = $ Complexity of Dynamics.\\
The new measurement should not increase the complexity of the dynamics. The last column must be a linear combination of the previous ones. (But we should know the order of the system $n-1$.)


%------------------------------
%------------------------------
\subsection{Multi-camera tracking}









%------------------------------
%------------------------------
\subsection{Multi-target tracking}
CHALLENGE:
\begin{itemize}
    \item Distinguishing similar looking targets is hard
    \item Trajectories not necessarily start/end at b image boundaries
\end{itemize}



%------------------------------
\section{Other}
The planar homography relates the transformation between two views when the scene is planar or the two views were generated by a camera rotating around its center of projection. It is a $3\times3$ matrix of rank 3. It has no information about the scene depth.\\

The Essential and Fundamental matrices completely describe the geometric relationship between corresponding points of a stereo pair. They are $3\times3$ matrices of rank 2. They provide the epipolar line of second image to search along once given a point in first image.\\

If two cameras have parallel optical axes and the line through the two centers of projection is perpendicular to the optic axes, the corresponding epipoles are at infinity.\\

Since the combination of affine transformations is also an affine transformation, the projection of a point in a planar scene at world coordinates $(X, Y)$ to pixel coordinates
$(u, v)$ in an image plane can be represented using a \textit{planar affine camera model}.\\

The affine viewing condition is small depth variation in the scene along the optic axis compared to its average distance from the camera. There are 6 $D.O.F.$ in the model. Minimum of 3 calibration points are needed to estimate the transformation. When an affine transform is applied to two parallel lines, the transformed lines will also be parallel.\\

Given a set of points $\textbf{p}_i = [x_i, y_i, 1]^T$ with $i = 1, ..., n$ from either side, we can define
\begin{equation*}
    \bar{x} = \frac{1}{n}\sum_{i=1}^nx_i,\ \bar{y} = \frac{1}{n}\sum_{i=1}^ny_i,\ \bar{d} = \frac{\sum_{i=1}^n\sqrt{(x_i - \bar{x})^2 + (y_i - \bar{y})^2 }}{n\sqrt{2}}
\end{equation*}
Solve $H\textbf{p}_i = \hat{\textbf{p}}_i$ for a $3\times3$ matrix $H$ with $\hat{\textbf{p}}_i = [(x_i - \bar{x})/d,\ (y_i - \bar{y})/d,\ i]^T$:
\begin{equation*}
H = \left[ \begin{array}{ccc}
1/d & 0 & -\bar{x}/d \\
0 & 1/d & -\bar{y}/d \\
0 & 0 & 1
\end{array} \right]
\end{equation*}



\end{multicols}
\end{document}
